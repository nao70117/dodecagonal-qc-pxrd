# -*- coding: utf-8 -*-
"""DNN_model_(4) (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SkiTsgDrfefjgHUuFhFHh2Q-nxOYImkE
"""

def dataset_labeled(multiQC_data, others_data):
    """
    generates labeled dataset
    """
    #aico = aico_min
    #print('Lattice constant [Å]', aico)

    myData = []
    # multiQC_data, others_data = dataset(wvl, QC_peaks, aico_min, aico_delta, hklmno_range, tth_min, tth_max, tth_step, data_num_qc, data_num_non_qc)

    # Multi-iQC
    #virtualQC_data = pxrd.calc_virtualiQC(data_num_qc, QC_peaks, wvl, aico, aico+aico_delta, tth_min, tth_max, tth_step)
    #multiQC_data = pxrd.calc_multiQC(virtualQC_data, tth_min, tth_max, tth_step)
    for i in multiQC_data:
        myData.append([i,1])

    # Non-iQC
    #others_data = pxrd.calc_others(data_num_non_qc, tth_min, tth_max, tth_step)
    for i in others_data:
        myData.append([i,0])

    random.shuffle(myData)
    x_data = []
    y_data = []
    for feature, label in myData:
        x_data.append(feature)
        y_data.append(label)

    #np.save('./x_data.npy', x_train)
    #np.save('./y_data.npy', y_train)
    x_data = np.array(x_data, dtype='float64')
    y_data = np.array(y_data, dtype='float64')

    return x_data, y_data

pip install optuna

from __future__ import absolute_import, division, print_function, unicode_literals
import os
import sys
import numpy as np
import random
import keras
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, Flatten, Conv1D ,Dropout, MaxPooling1D ,InputLayer
# from keras.layers.pooling import GlobalMaxPooling1D
from tensorflow.keras.layers import GlobalMaxPooling1D
from keras import regularizers
import glob
import math
import optuna
from tensorflow.keras import Sequential
import gc

dic_wvl = {}
dic_wvl['Cu_Ka'] = 1.54059


path_model = './models'
if os.path.isdir('%s'%(path_model))==False:
    os.mkdir('%s'%(path_model))


##トレーニング用データ
multiQC_data = np.load('/content/drive/MyDrive/virtual_QC/training_dodeca.npy')
others_data = np.load('/content/drive/MyDrive/virtual_QC/training_others.npy')
x_train, y_train = dataset_labeled(multiQC_data, others_data)

##テスト用データ
multiQC_test = np.load('/content/drive/MyDrive/virtual_QC/test_dodeca.npy')
others_test = np.load('/content/drive/MyDrive/virtual_QC/test_others.npy')
x_test, y_test = dataset_labeled(multiQC_test, others_test)

input_=x_train.shape[1]
# tf.keras.backend.set_floatx('float64')
x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]


# Optunaの目的関数
def objective(trial):
    # ハイパーパラメータの探索範囲を定義
    # num_conv_layers = trial.suggest_int("num_conv_layers", 1, 4, step=1)  # 畳み込み層の数
    num_conv_layers = 3
    # conv_filters = trial.suggest_int("conv_filters", 32, 128, step=32)  # 畳み込み層のフィルター数
    conv_filters = 64
    # kernel_size = trial.suggest_int("kernel_size", 10, 50, step=10)  # 畳み込み層のフィルターサイズ
    kernel_size = 30
    # strides = trial.suggest_int("strides", 1, 3, step=1)  # 畳み込み層のストライド
    strides = 3
    # pool_size = trial.suggest_int("pool_size", 1, 3, step=1)  # プーリング層のプールサイズ
    pool_size = 1
    # pool_strides = trial.suggest_int("pool_strides", 1, 3, step=1)  # プーリング層のストライド
    pool_strides = 2
    # num_dense_layers = trial.suggest_int("num_dense_layers", 1, 3, step=1)  # 全結合層の数
    num_dense_layers = 2
    # dense_units = trial.suggest_int("dense_units", 500, 3000, step=500)  #全結合層のニューロン数
    dense_units = 1000

    # dense_units = trial.suggest_int("dense_units", 64, 256, step=32)  # 最初の全結合層のユニット数

    # dropout_rate = trial.suggest_float("dropout_rate", 0.0, 0.5, step=0.1)  #Dropout
    dropout_rate = 0.5
    # optimizer_name = trial.suggest_categorical("optimizer", ["adam", "sgd", "rmsprop", "adagrad"])  #最適化アルゴリズム

    optimizer_name = trial.suggest_categorical("optimizer", ["adam", "sgd"])  #最適化アルゴリズム
    # optimizer_name = "adam"

    # learning_rate = trial.suggest_float("learning_rate", 1e-4, 1e-2, log=True)  #学習率
    learning_rate = 0.001
    # reduction_factor = trial.suggest_float("reduction_factor", 0.5, 1.0, step=0.1)  # 層ごとのユニット数の減少率
    reduction_factor = 0.5
    # batch_num = trial.suggest_int("batch_size", 32, 256, step=32)  #パッチサイズ
    batch_num=256
    # epoch_num = trial.suggest_int("epochs", 5, 25, step=5)  #エポック数
    epoch_num=15

    # 選択されたoptimizerを設定
    if optimizer_name == "adam":
        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
    elif optimizer_name == "sgd":
        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)
    # elif optimizer_name == "rmsprop":
    #     optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)
    # elif optimizer_name == "adagrad":
    #     optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)

    # モデルの構築
    model = Sequential()
    for i in range(num_conv_layers):  # 畳み込み層を動的に追加
        if i == 0:
            # 最初の畳み込み層（input_shapeを指定）
            model.add(Conv1D(conv_filters, kernel_size=kernel_size, strides=strides, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))
        else:
            # 2層目以降の畳み込み層
            model.add(Conv1D(conv_filters, kernel_size=kernel_size, strides=strides, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))
        model.add(MaxPooling1D(pool_size,  strides=pool_strides, padding='valid'))

    # # Flattenで入力を整形
    model.add(Flatten())

    # 全結合層を追加
    for i in range(num_dense_layers):
        model.add(Dense(dense_units, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
        model.add(Dropout(dropout_rate))
        dense_units = int(dense_units * reduction_factor)  # ユニット数を減少

    # 出力層
    model.add(Dense(2, activation='sigmoid'))

    # Optimizerの設定
    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

    #最適化アルゴリズム, 損失関数(Sparse Categorical CrossEntropy)
    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # モデルのトレーニング
    training_model = model.fit(x_train, y_train, epochs=epoch_num, batch_size=batch_num, validation_split=0.2)

    model.evaluate(x_test, y_test, verbose=2)

    # 検証データの精度を最適化対象とする
    val_accuracy = max(training_model.history['val_accuracy'])

    # GPUメモリを解放
    tf.keras.backend.clear_session()
    gc.collect()

    return val_accuracy

# Optunaのスタディを作成して最適化を実行
study = optuna.create_study(direction="maximize")  # 検証精度を最大化
study.optimize(objective, n_trials=6)  # 試行回数を指定

# 最適な結果を表示
print("Best Trial:")
print(f"  Accuracy: {study.best_value}")
print(f"  Params: {study.best_params}")

from __future__ import absolute_import, division, print_function, unicode_literals
import os
import sys
import numpy as np
import random
import keras
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, Flatten, Conv1D ,Dropout, MaxPooling1D ,InputLayer
# from keras.layers.pooling import GlobalMaxPooling1D
from tensorflow.keras.layers import GlobalMaxPooling1D
from keras import regularizers
import glob
import math
# import generator as gen

dic_wvl = {}
dic_wvl['Cu_Ka'] = 1.54059


path_model = './models'
if os.path.isdir('%s'%(path_model))==False:
    os.mkdir('%s'%(path_model))



num_all = 1
for i in range(num_all):


    ##トレーニング用データ
    multiQC_data = np.load('/content/drive/MyDrive/virtual_QC/training_dodeca.npy')
    others_data = np.load('/content/drive/MyDrive/virtual_QC/training_others.npy')
    x_train, y_train = dataset_labeled(multiQC_data, others_data)

    ##テスト用データ
    multiQC_test = np.load('/content/drive/MyDrive/virtual_QC/test_dodeca.npy')
    others_test = np.load('/content/drive/MyDrive/virtual_QC/test_others.npy')
    x_test, y_test = dataset_labeled(multiQC_test, others_test)

    input_=x_train.shape[1]
    # tf.keras.backend.set_floatx('float64')
    x_train = x_train[..., tf.newaxis]
    x_test = x_test[..., tf.newaxis]

    ##ベイズ最適化を行ったDNNモデル
    class MyModel(Model):
        def __init__(self):
            super(MyModel, self).__init__()

            ##Conv(畳み込み層) MaxPooling(プーリング層)
            #畳み込み層1
            self.conv1 = Conv1D(64,20, strides=1, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))
            #プーリング層1
            self.mp1 = MaxPooling1D(3,  strides=3, padding='valid')
            #以下同様
            self.conv2 = Conv1D(64,20, strides=1, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))
            self.mp2 = MaxPooling1D(2,  strides=3, padding='valid')
            self.conv3 = Conv1D(64,20, strides=2, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))
            self.mp3 = MaxPooling1D(1,  strides=2, padding='valid')
            # Flattenレイヤーを使って1次元に変換 (1次元化:21376)
            self.flatten = Flatten()
            #全結合層1
            self.d1 = Dense(2000, activation='relu', kernel_regularizer=regularizers.l2(0.01))
            self.do1 = Dropout(0.5)
            #全結合層2
            self.d2 = Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01))
            self.do2 = Dropout(0.5)
            #出力
            self.ds = Dense(2, activation='softmax')

        def call(self, x):
            x = self.conv1(x)
            print(x.shape)
            x = self.mp1(x)
            print(x.shape)
            x = self.conv2(x)
            print(x.shape)
            x = self.mp2(x)
            print(x.shape)
            x = self.conv3(x)
            print(x.shape)
            x = self.mp3(x)
            x = self.flatten(x)
            print(x.shape)
            x = self.d1(x)
            x = self.do1(x)
            x = self.d2(x)
            x = self.do2(x)
            y = self.ds(x)
            return y

    #定義したDNNモデル
    model = MyModel()
    #エポック数
    epoch_num=13
    #バッチサイズ
    batch_num=128

    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)


    #最適化アルゴリズム(Adam), 損失関数(Sparse Categorical CrossEntropy)
    model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

    training_model = model.fit(x_train, y_train, epochs=epoch_num, batch_size=batch_num, validation_split=0.2)
    model.evaluate(x_test, y_test, verbose=2)

    model_name='test_model'
    model.export('%s/'%(path_model)+model_name)
    model.save('%s/my_model.h5'%(path_model))

model.evaluate(x_test, y_test, verbose=2)

accuracy = training_model.history['accuracy']
val_accuracy = training_model.history['val_accuracy']
loss = training_model.history['loss']
val_loss = training_model.history['val_loss']

MultiQC_test = np.load('/content/drive/MyDrive/virtual_QC/test_dodeca.npy')
others_test = np.load('/content/drive/MyDrive/virtual_QC/test_others.npy')
MultiQC_test = MultiQC_test.reshape(3000, 6000, 1)
others_test = others_test.reshape(3000, 6000, 1)

Result_QC = np.round(model.predict(MultiQC_test)[:, 1]).astype(int)
Result_others = np.round(model.predict(others_test)[:, 1]).astype(int)

print('Prediction result')
print('QC : ', len(Result_QC), ', Others : ', len(Result_others))
print(Result_others)
print(Result_QC)

MultiQC=model.predict(MultiQC_test)
print(MultiQC)

others=model.predict(others_test)
print(others)

data = list(MultiQC)
left_elements = [arr[1] for arr in data]
count_greater_than_0_5 = len([x for x in left_elements if x > 0.5])
TP=count_greater_than_0_5
FN=len(Result_QC)-count_greater_than_0_5
print("TP:", TP)
print("FN:", FN)

data = list(others)
left_elements = [arr[0] for arr in data]
count_greater_than_0_5 = len([x for x in left_elements if x > 0.5])
FP=len(Result_others)-count_greater_than_0_5
TN=count_greater_than_0_5
print("FP:", FP)
print("TN:", TN)

Accuracy=(TP+TN)/(TP+TN+FP+FN)
Recall=1-FN/(TP+FN)
Precision=1-FP/(TP+FP)


print("Accuracy:", Accuracy)
print("Recall:", Recall)
print("Precision:", Precision)

import matplotlib.pyplot as plt



plt.plot(training_model.history['accuracy'], label='Training Accuracy')
plt.plot(training_model.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()


plt.show()

import matplotlib.pyplot as plt


plt.plot(training_model.history['loss'], label='Training Loss')
plt.plot(training_model.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()


plt.show()

import matplotlib.pyplot as plt

def plot_loss_vs_accuracy(loss, accuracy, val_loss, val_accuracy):
    """
    損失と精度の関係をプロットする関数

    Parameters:
        loss (list): トレーニングデータの損失リスト
        accuracy (list): トレーニングデータの精度リスト
        val_loss (list): 検証データの損失リスト
        val_accuracy (list): 検証データの精度リスト
    """
    plt.figure(figsize=(6, 6))
    plt.scatter(loss, accuracy, color='blue', label='Training (Loss vs Accuracy)')
    plt.scatter(val_loss, val_accuracy, color='red', label='Validation (Loss vs Accuracy)')
    plt.title('Accuracy vs Loss')
    plt.xlabel('Loss')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    plt.show()


plot_loss_vs_accuracy(loss, accuracy, val_loss, val_accuracy)

# import numpy as np
# data = list(MultiQC)

# # print(data)



# # 各 array の左側の要素（最初の値）を取り出す
# left_elements = [arr[1] for arr in data]

# # 結果を表示
# print("左側の要素のみ:", left_elements)

# # 0.5より大きい要素を数える
# count_greater_than_0_5 = len([x for x in left_elements if x > 0.5])

# # 結果を表示
# print("0.5より大きい要素の数:", count_greater_than_0_5)

